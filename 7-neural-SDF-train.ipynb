{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb, math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pdb\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SDF, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 512)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 512)     \n",
    "        self.fc6 = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         pdb.set_trace()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "coords = np.load('coords.npy')\n",
    "SDFs = np.load('SDF.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = [i for i, s in enumerate(SDFs) if s<20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SDFDataset(Dataset):\n",
    "\n",
    "    def __init__(self,coords,SDFs):\n",
    "       \n",
    "        self.coords = coords\n",
    "        self.SDFs = SDFs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.SDFs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        coord = torch.from_numpy(self.coords[idx])\n",
    "        sdf = torch.from_numpy(np.array(self.SDFs[idx])).unsqueeze(0)\n",
    "#         pdb.set_trace()\n",
    "        sample = {'coords': coord, 'sdf': sdf}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils import data\n",
    "dataset = SDFDataset(coords,SDFs)\n",
    "\n",
    "idx = list(range(len(coords)))\n",
    "random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
    "train_idx = idx[:int(len(coords)*0.8)]\n",
    "test_idx = idx[int(len(coords)*0.8):]\n",
    "\n",
    "train_set = data.Subset(dataset, train_idx)\n",
    "test_set = data.Subset(dataset, test_idx)\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=512,\n",
    "                        shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_set, batch_size=512,\n",
    "                        shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392256.80000000005"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coords)*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "#         pdb.set_trace()\n",
    "        data, target = sample['coords'].to(device), sample['sdf'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "        loss = F.l1_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, device, test_loader, optimizer, epoch, best_loss=1):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for batch_idx, sample in enumerate(test_loader):\n",
    "        data, target = sample['coords'].to(device), sample['sdf'].to(device)\n",
    "        output = model(data)\n",
    "        loss = F.l1_loss(output, target)\n",
    "        losses.append(loss)\n",
    "#     pdb.set_trace()\n",
    "    loss = sum(losses)/len(losses)\n",
    "    print(f'test loss:{loss}')\n",
    "    if loss<best_loss:\n",
    "        torch.save(model.state_dict(), 'sdf.torch')\n",
    "        best_loss = loss\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = SDF().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/392256 (0%)]\tLoss: 6.488205\n",
      "Train Epoch: 1 [51200/392256 (13%)]\tLoss: 5.590211\n",
      "Train Epoch: 1 [102400/392256 (26%)]\tLoss: 1.074756\n",
      "Train Epoch: 1 [153600/392256 (39%)]\tLoss: 1.003680\n",
      "Train Epoch: 1 [204800/392256 (52%)]\tLoss: 0.785843\n",
      "Train Epoch: 1 [256000/392256 (65%)]\tLoss: 0.672025\n",
      "Train Epoch: 1 [307200/392256 (78%)]\tLoss: 0.586334\n",
      "Train Epoch: 1 [358400/392256 (91%)]\tLoss: 0.464577\n",
      "test loss:0.3255421817302704\n",
      "Train Epoch: 2 [0/392256 (0%)]\tLoss: 0.305795\n",
      "Train Epoch: 2 [51200/392256 (13%)]\tLoss: 0.160061\n",
      "Train Epoch: 2 [102400/392256 (26%)]\tLoss: 0.118831\n",
      "Train Epoch: 2 [153600/392256 (39%)]\tLoss: 0.117776\n",
      "Train Epoch: 2 [204800/392256 (52%)]\tLoss: 0.059922\n",
      "Train Epoch: 2 [256000/392256 (65%)]\tLoss: 0.072693\n",
      "Train Epoch: 2 [307200/392256 (78%)]\tLoss: 0.051957\n",
      "Train Epoch: 2 [358400/392256 (91%)]\tLoss: 0.065199\n",
      "test loss:0.04084573686122894\n",
      "Train Epoch: 3 [0/392256 (0%)]\tLoss: 0.040038\n",
      "Train Epoch: 3 [51200/392256 (13%)]\tLoss: 0.042856\n",
      "Train Epoch: 3 [102400/392256 (26%)]\tLoss: 0.037939\n",
      "Train Epoch: 3 [153600/392256 (39%)]\tLoss: 0.035561\n",
      "Train Epoch: 3 [204800/392256 (52%)]\tLoss: 0.045707\n",
      "Train Epoch: 3 [256000/392256 (65%)]\tLoss: 0.034806\n",
      "Train Epoch: 3 [307200/392256 (78%)]\tLoss: 0.065307\n",
      "Train Epoch: 3 [358400/392256 (91%)]\tLoss: 0.061355\n",
      "test loss:0.027749888598918915\n",
      "Train Epoch: 4 [0/392256 (0%)]\tLoss: 0.026783\n",
      "Train Epoch: 4 [51200/392256 (13%)]\tLoss: 0.023759\n",
      "Train Epoch: 4 [102400/392256 (26%)]\tLoss: 0.033561\n",
      "Train Epoch: 4 [153600/392256 (39%)]\tLoss: 0.036817\n",
      "Train Epoch: 4 [204800/392256 (52%)]\tLoss: 0.023500\n",
      "Train Epoch: 4 [256000/392256 (65%)]\tLoss: 0.022115\n",
      "Train Epoch: 4 [307200/392256 (78%)]\tLoss: 0.022562\n",
      "Train Epoch: 4 [358400/392256 (91%)]\tLoss: 0.018462\n",
      "test loss:0.022263143211603165\n",
      "Train Epoch: 5 [0/392256 (0%)]\tLoss: 0.021393\n",
      "Train Epoch: 5 [51200/392256 (13%)]\tLoss: 0.047571\n",
      "Train Epoch: 5 [102400/392256 (26%)]\tLoss: 0.041369\n",
      "Train Epoch: 5 [153600/392256 (39%)]\tLoss: 0.021035\n",
      "Train Epoch: 5 [204800/392256 (52%)]\tLoss: 0.023961\n",
      "Train Epoch: 5 [256000/392256 (65%)]\tLoss: 0.060749\n",
      "Train Epoch: 5 [307200/392256 (78%)]\tLoss: 0.020173\n",
      "Train Epoch: 5 [358400/392256 (91%)]\tLoss: 0.017055\n",
      "test loss:0.021977894008159637\n",
      "Train Epoch: 6 [0/392256 (0%)]\tLoss: 0.019155\n",
      "Train Epoch: 6 [51200/392256 (13%)]\tLoss: 0.017749\n",
      "Train Epoch: 6 [102400/392256 (26%)]\tLoss: 0.015338\n",
      "Train Epoch: 6 [153600/392256 (39%)]\tLoss: 0.025706\n",
      "Train Epoch: 6 [204800/392256 (52%)]\tLoss: 0.018758\n",
      "Train Epoch: 6 [256000/392256 (65%)]\tLoss: 0.015311\n",
      "Train Epoch: 6 [307200/392256 (78%)]\tLoss: 0.022525\n",
      "Train Epoch: 6 [358400/392256 (91%)]\tLoss: 0.020662\n",
      "test loss:0.03616590425372124\n",
      "Train Epoch: 7 [0/392256 (0%)]\tLoss: 0.032610\n",
      "Train Epoch: 7 [51200/392256 (13%)]\tLoss: 0.021604\n",
      "Train Epoch: 7 [102400/392256 (26%)]\tLoss: 0.022128\n",
      "Train Epoch: 7 [153600/392256 (39%)]\tLoss: 0.013815\n",
      "Train Epoch: 7 [204800/392256 (52%)]\tLoss: 0.031067\n",
      "Train Epoch: 7 [256000/392256 (65%)]\tLoss: 0.018335\n",
      "Train Epoch: 7 [307200/392256 (78%)]\tLoss: 0.026203\n",
      "Train Epoch: 7 [358400/392256 (91%)]\tLoss: 0.027752\n",
      "test loss:0.02868022583425045\n",
      "Train Epoch: 8 [0/392256 (0%)]\tLoss: 0.025913\n",
      "Train Epoch: 8 [51200/392256 (13%)]\tLoss: 0.013688\n",
      "Train Epoch: 8 [102400/392256 (26%)]\tLoss: 0.013761\n",
      "Train Epoch: 8 [153600/392256 (39%)]\tLoss: 0.017598\n",
      "Train Epoch: 8 [204800/392256 (52%)]\tLoss: 0.018022\n",
      "Train Epoch: 8 [256000/392256 (65%)]\tLoss: 0.042790\n",
      "Train Epoch: 8 [307200/392256 (78%)]\tLoss: 0.013638\n",
      "Train Epoch: 8 [358400/392256 (91%)]\tLoss: 0.012724\n",
      "test loss:0.025703884661197662\n",
      "Train Epoch: 9 [0/392256 (0%)]\tLoss: 0.025756\n",
      "Train Epoch: 9 [51200/392256 (13%)]\tLoss: 0.059783\n",
      "Train Epoch: 9 [102400/392256 (26%)]\tLoss: 0.017420\n",
      "Train Epoch: 9 [153600/392256 (39%)]\tLoss: 0.015308\n",
      "Train Epoch: 9 [204800/392256 (52%)]\tLoss: 0.013515\n",
      "Train Epoch: 9 [256000/392256 (65%)]\tLoss: 0.012648\n",
      "Train Epoch: 9 [307200/392256 (78%)]\tLoss: 0.021335\n",
      "Train Epoch: 9 [358400/392256 (91%)]\tLoss: 0.014995\n",
      "test loss:0.013324443250894547\n",
      "Train Epoch: 10 [0/392256 (0%)]\tLoss: 0.012233\n",
      "Train Epoch: 10 [51200/392256 (13%)]\tLoss: 0.021509\n",
      "Train Epoch: 10 [102400/392256 (26%)]\tLoss: 0.028147\n",
      "Train Epoch: 10 [153600/392256 (39%)]\tLoss: 0.053425\n",
      "Train Epoch: 10 [204800/392256 (52%)]\tLoss: 0.022666\n",
      "Train Epoch: 10 [256000/392256 (65%)]\tLoss: 0.018266\n",
      "Train Epoch: 10 [307200/392256 (78%)]\tLoss: 0.013272\n",
      "Train Epoch: 10 [358400/392256 (91%)]\tLoss: 0.013871\n",
      "test loss:0.025219369679689407\n",
      "Train Epoch: 11 [0/392256 (0%)]\tLoss: 0.025275\n",
      "Train Epoch: 11 [51200/392256 (13%)]\tLoss: 0.011525\n",
      "Train Epoch: 11 [102400/392256 (26%)]\tLoss: 0.015200\n",
      "Train Epoch: 11 [153600/392256 (39%)]\tLoss: 0.020309\n",
      "Train Epoch: 11 [204800/392256 (52%)]\tLoss: 0.055183\n",
      "Train Epoch: 11 [256000/392256 (65%)]\tLoss: 0.051753\n",
      "Train Epoch: 11 [307200/392256 (78%)]\tLoss: 0.040617\n",
      "Train Epoch: 11 [358400/392256 (91%)]\tLoss: 0.014922\n",
      "test loss:0.012901372276246548\n",
      "Train Epoch: 12 [0/392256 (0%)]\tLoss: 0.011751\n",
      "Train Epoch: 12 [51200/392256 (13%)]\tLoss: 0.050495\n",
      "Train Epoch: 12 [102400/392256 (26%)]\tLoss: 0.035713\n",
      "Train Epoch: 12 [153600/392256 (39%)]\tLoss: 0.021359\n",
      "Train Epoch: 12 [204800/392256 (52%)]\tLoss: 0.016765\n",
      "Train Epoch: 12 [256000/392256 (65%)]\tLoss: 0.032846\n",
      "Train Epoch: 12 [307200/392256 (78%)]\tLoss: 0.012508\n",
      "Train Epoch: 12 [358400/392256 (91%)]\tLoss: 0.012172\n",
      "test loss:0.027813520282506943\n",
      "Train Epoch: 13 [0/392256 (0%)]\tLoss: 0.028559\n",
      "Train Epoch: 13 [51200/392256 (13%)]\tLoss: 0.010917\n",
      "Train Epoch: 13 [102400/392256 (26%)]\tLoss: 0.011729\n",
      "Train Epoch: 13 [153600/392256 (39%)]\tLoss: 0.010361\n",
      "Train Epoch: 13 [204800/392256 (52%)]\tLoss: 0.016061\n",
      "Train Epoch: 13 [256000/392256 (65%)]\tLoss: 0.019038\n",
      "Train Epoch: 13 [307200/392256 (78%)]\tLoss: 0.024110\n",
      "Train Epoch: 13 [358400/392256 (91%)]\tLoss: 0.012689\n",
      "test loss:0.07501555234193802\n",
      "Train Epoch: 14 [0/392256 (0%)]\tLoss: 0.082113\n",
      "Train Epoch: 14 [51200/392256 (13%)]\tLoss: 0.011338\n",
      "Train Epoch: 14 [102400/392256 (26%)]\tLoss: 0.061250\n",
      "Train Epoch: 14 [153600/392256 (39%)]\tLoss: 0.011032\n",
      "Train Epoch: 14 [204800/392256 (52%)]\tLoss: 0.023583\n",
      "Train Epoch: 14 [256000/392256 (65%)]\tLoss: 0.013126\n",
      "Train Epoch: 14 [307200/392256 (78%)]\tLoss: 0.015598\n",
      "Train Epoch: 14 [358400/392256 (91%)]\tLoss: 0.021319\n",
      "test loss:0.011553126387298107\n",
      "Train Epoch: 15 [0/392256 (0%)]\tLoss: 0.011212\n",
      "Train Epoch: 15 [51200/392256 (13%)]\tLoss: 0.010120\n",
      "Train Epoch: 15 [102400/392256 (26%)]\tLoss: 0.031050\n",
      "Train Epoch: 15 [153600/392256 (39%)]\tLoss: 0.018874\n",
      "Train Epoch: 15 [204800/392256 (52%)]\tLoss: 0.017611\n",
      "Train Epoch: 15 [256000/392256 (65%)]\tLoss: 0.011861\n",
      "Train Epoch: 15 [307200/392256 (78%)]\tLoss: 0.009900\n",
      "Train Epoch: 15 [358400/392256 (91%)]\tLoss: 0.009787\n",
      "test loss:0.02900284342467785\n",
      "Train Epoch: 16 [0/392256 (0%)]\tLoss: 0.032029\n",
      "Train Epoch: 16 [51200/392256 (13%)]\tLoss: 0.034873\n",
      "Train Epoch: 16 [102400/392256 (26%)]\tLoss: 0.010771\n",
      "Train Epoch: 16 [153600/392256 (39%)]\tLoss: 0.011099\n",
      "Train Epoch: 16 [204800/392256 (52%)]\tLoss: 0.015308\n",
      "Train Epoch: 16 [256000/392256 (65%)]\tLoss: 0.011059\n",
      "Train Epoch: 16 [307200/392256 (78%)]\tLoss: 0.009483\n",
      "Train Epoch: 16 [358400/392256 (91%)]\tLoss: 0.011996\n",
      "test loss:0.01914745196700096\n",
      "Train Epoch: 17 [0/392256 (0%)]\tLoss: 0.018418\n",
      "Train Epoch: 17 [51200/392256 (13%)]\tLoss: 0.017943\n",
      "Train Epoch: 17 [102400/392256 (26%)]\tLoss: 0.009813\n",
      "Train Epoch: 17 [153600/392256 (39%)]\tLoss: 0.009989\n",
      "Train Epoch: 17 [204800/392256 (52%)]\tLoss: 0.015429\n",
      "Train Epoch: 17 [256000/392256 (65%)]\tLoss: 0.012526\n",
      "Train Epoch: 17 [307200/392256 (78%)]\tLoss: 0.025658\n",
      "Train Epoch: 17 [358400/392256 (91%)]\tLoss: 0.011290\n",
      "test loss:0.01958322711288929\n",
      "Train Epoch: 18 [0/392256 (0%)]\tLoss: 0.020260\n",
      "Train Epoch: 18 [51200/392256 (13%)]\tLoss: 0.008926\n",
      "Train Epoch: 18 [102400/392256 (26%)]\tLoss: 0.037437\n",
      "Train Epoch: 18 [153600/392256 (39%)]\tLoss: 0.009547\n",
      "Train Epoch: 18 [204800/392256 (52%)]\tLoss: 0.014947\n",
      "Train Epoch: 18 [256000/392256 (65%)]\tLoss: 0.013588\n",
      "Train Epoch: 18 [307200/392256 (78%)]\tLoss: 0.011476\n",
      "Train Epoch: 18 [358400/392256 (91%)]\tLoss: 0.018416\n",
      "test loss:0.04791739583015442\n",
      "Train Epoch: 19 [0/392256 (0%)]\tLoss: 0.049401\n",
      "Train Epoch: 19 [51200/392256 (13%)]\tLoss: 0.010017\n",
      "Train Epoch: 19 [102400/392256 (26%)]\tLoss: 0.012248\n",
      "Train Epoch: 19 [153600/392256 (39%)]\tLoss: 0.027461\n",
      "Train Epoch: 19 [204800/392256 (52%)]\tLoss: 0.043634\n",
      "Train Epoch: 19 [256000/392256 (65%)]\tLoss: 0.015540\n",
      "Train Epoch: 19 [307200/392256 (78%)]\tLoss: 0.020935\n",
      "Train Epoch: 19 [358400/392256 (91%)]\tLoss: 0.020649\n",
      "test loss:0.009777611121535301\n",
      "Train Epoch: 20 [0/392256 (0%)]\tLoss: 0.009627\n",
      "Train Epoch: 20 [51200/392256 (13%)]\tLoss: 0.013563\n",
      "Train Epoch: 20 [102400/392256 (26%)]\tLoss: 0.013099\n",
      "Train Epoch: 20 [153600/392256 (39%)]\tLoss: 0.010212\n",
      "Train Epoch: 20 [204800/392256 (52%)]\tLoss: 0.032378\n",
      "Train Epoch: 20 [256000/392256 (65%)]\tLoss: 0.013979\n",
      "Train Epoch: 20 [307200/392256 (78%)]\tLoss: 0.011634\n",
      "Train Epoch: 20 [358400/392256 (91%)]\tLoss: 0.024628\n",
      "test loss:0.017027728259563446\n",
      "Train Epoch: 21 [0/392256 (0%)]\tLoss: 0.017066\n",
      "Train Epoch: 21 [51200/392256 (13%)]\tLoss: 0.025556\n",
      "Train Epoch: 21 [102400/392256 (26%)]\tLoss: 0.021715\n",
      "Train Epoch: 21 [153600/392256 (39%)]\tLoss: 0.038892\n",
      "Train Epoch: 21 [204800/392256 (52%)]\tLoss: 0.031809\n",
      "Train Epoch: 21 [256000/392256 (65%)]\tLoss: 0.010775\n",
      "Train Epoch: 21 [307200/392256 (78%)]\tLoss: 0.074779\n",
      "Train Epoch: 21 [358400/392256 (91%)]\tLoss: 0.019476\n",
      "test loss:0.026687337085604668\n",
      "Train Epoch: 22 [0/392256 (0%)]\tLoss: 0.026494\n",
      "Train Epoch: 22 [51200/392256 (13%)]\tLoss: 0.021794\n",
      "Train Epoch: 22 [102400/392256 (26%)]\tLoss: 0.018179\n",
      "Train Epoch: 22 [153600/392256 (39%)]\tLoss: 0.015056\n",
      "Train Epoch: 22 [204800/392256 (52%)]\tLoss: 0.019125\n",
      "Train Epoch: 22 [256000/392256 (65%)]\tLoss: 0.012041\n",
      "Train Epoch: 22 [307200/392256 (78%)]\tLoss: 0.009453\n",
      "Train Epoch: 22 [358400/392256 (91%)]\tLoss: 0.029783\n",
      "test loss:0.012741043232381344\n",
      "Train Epoch: 23 [0/392256 (0%)]\tLoss: 0.011626\n",
      "Train Epoch: 23 [51200/392256 (13%)]\tLoss: 0.024406\n",
      "Train Epoch: 23 [102400/392256 (26%)]\tLoss: 0.030804\n",
      "Train Epoch: 23 [153600/392256 (39%)]\tLoss: 0.009123\n",
      "Train Epoch: 23 [204800/392256 (52%)]\tLoss: 0.012996\n",
      "Train Epoch: 23 [256000/392256 (65%)]\tLoss: 0.010957\n",
      "Train Epoch: 23 [307200/392256 (78%)]\tLoss: 0.012710\n",
      "Train Epoch: 23 [358400/392256 (91%)]\tLoss: 0.015313\n",
      "test loss:0.01030853670090437\n",
      "Train Epoch: 24 [0/392256 (0%)]\tLoss: 0.010722\n",
      "Train Epoch: 24 [51200/392256 (13%)]\tLoss: 0.012259\n",
      "Train Epoch: 24 [102400/392256 (26%)]\tLoss: 0.027041\n",
      "Train Epoch: 24 [153600/392256 (39%)]\tLoss: 0.009402\n",
      "Train Epoch: 24 [204800/392256 (52%)]\tLoss: 0.025583\n",
      "Train Epoch: 24 [256000/392256 (65%)]\tLoss: 0.017457\n",
      "Train Epoch: 24 [307200/392256 (78%)]\tLoss: 0.013987\n",
      "Train Epoch: 24 [358400/392256 (91%)]\tLoss: 0.027161\n",
      "test loss:0.009879495948553085\n",
      "Train Epoch: 25 [0/392256 (0%)]\tLoss: 0.010170\n",
      "Train Epoch: 25 [51200/392256 (13%)]\tLoss: 0.044196\n",
      "Train Epoch: 25 [102400/392256 (26%)]\tLoss: 0.012632\n",
      "Train Epoch: 25 [153600/392256 (39%)]\tLoss: 0.008734\n",
      "Train Epoch: 25 [204800/392256 (52%)]\tLoss: 0.009668\n",
      "Train Epoch: 25 [256000/392256 (65%)]\tLoss: 0.024396\n",
      "Train Epoch: 25 [307200/392256 (78%)]\tLoss: 0.035360\n",
      "Train Epoch: 25 [358400/392256 (91%)]\tLoss: 0.037018\n",
      "test loss:0.019253626465797424\n",
      "Train Epoch: 26 [0/392256 (0%)]\tLoss: 0.018670\n",
      "Train Epoch: 26 [51200/392256 (13%)]\tLoss: 0.018698\n",
      "Train Epoch: 26 [102400/392256 (26%)]\tLoss: 0.014598\n",
      "Train Epoch: 26 [153600/392256 (39%)]\tLoss: 0.025036\n",
      "Train Epoch: 26 [204800/392256 (52%)]\tLoss: 0.041288\n",
      "Train Epoch: 26 [256000/392256 (65%)]\tLoss: 0.013109\n",
      "Train Epoch: 26 [307200/392256 (78%)]\tLoss: 0.016549\n",
      "Train Epoch: 26 [358400/392256 (91%)]\tLoss: 0.011711\n",
      "test loss:0.027018778026103973\n",
      "Train Epoch: 27 [0/392256 (0%)]\tLoss: 0.024957\n",
      "Train Epoch: 27 [51200/392256 (13%)]\tLoss: 0.009361\n",
      "Train Epoch: 27 [102400/392256 (26%)]\tLoss: 0.008928\n",
      "Train Epoch: 27 [153600/392256 (39%)]\tLoss: 0.008671\n",
      "Train Epoch: 27 [204800/392256 (52%)]\tLoss: 0.008419\n",
      "Train Epoch: 27 [256000/392256 (65%)]\tLoss: 0.013237\n",
      "Train Epoch: 27 [307200/392256 (78%)]\tLoss: 0.020925\n",
      "Train Epoch: 27 [358400/392256 (91%)]\tLoss: 0.008858\n",
      "test loss:0.012442559003829956\n",
      "Train Epoch: 28 [0/392256 (0%)]\tLoss: 0.013146\n",
      "Train Epoch: 28 [51200/392256 (13%)]\tLoss: 0.010622\n",
      "Train Epoch: 28 [102400/392256 (26%)]\tLoss: 0.013263\n",
      "Train Epoch: 28 [153600/392256 (39%)]\tLoss: 0.008469\n",
      "Train Epoch: 28 [204800/392256 (52%)]\tLoss: 0.037028\n",
      "Train Epoch: 28 [256000/392256 (65%)]\tLoss: 0.013637\n",
      "Train Epoch: 28 [307200/392256 (78%)]\tLoss: 0.010909\n",
      "Train Epoch: 28 [358400/392256 (91%)]\tLoss: 0.016923\n",
      "test loss:0.03619873523712158\n",
      "Train Epoch: 29 [0/392256 (0%)]\tLoss: 0.033809\n",
      "Train Epoch: 29 [51200/392256 (13%)]\tLoss: 0.026117\n",
      "Train Epoch: 29 [102400/392256 (26%)]\tLoss: 0.021257\n",
      "Train Epoch: 29 [153600/392256 (39%)]\tLoss: 0.025170\n",
      "Train Epoch: 29 [204800/392256 (52%)]\tLoss: 0.024339\n",
      "Train Epoch: 29 [256000/392256 (65%)]\tLoss: 0.035644\n",
      "Train Epoch: 29 [307200/392256 (78%)]\tLoss: 0.008375\n",
      "Train Epoch: 29 [358400/392256 (91%)]\tLoss: 0.013009\n",
      "test loss:0.027903428301215172\n",
      "Train Epoch: 30 [0/392256 (0%)]\tLoss: 0.031029\n",
      "Train Epoch: 30 [51200/392256 (13%)]\tLoss: 0.009321\n",
      "Train Epoch: 30 [102400/392256 (26%)]\tLoss: 0.022143\n",
      "Train Epoch: 30 [153600/392256 (39%)]\tLoss: 0.020857\n",
      "Train Epoch: 30 [204800/392256 (52%)]\tLoss: 0.007326\n",
      "Train Epoch: 30 [256000/392256 (65%)]\tLoss: 0.008781\n",
      "Train Epoch: 30 [307200/392256 (78%)]\tLoss: 0.025243\n",
      "Train Epoch: 30 [358400/392256 (91%)]\tLoss: 0.009887\n",
      "test loss:0.040136806666851044\n",
      "Train Epoch: 31 [0/392256 (0%)]\tLoss: 0.038589\n",
      "Train Epoch: 31 [51200/392256 (13%)]\tLoss: 0.021825\n",
      "Train Epoch: 31 [102400/392256 (26%)]\tLoss: 0.018802\n",
      "Train Epoch: 31 [153600/392256 (39%)]\tLoss: 0.013313\n",
      "Train Epoch: 31 [204800/392256 (52%)]\tLoss: 0.012670\n",
      "Train Epoch: 31 [256000/392256 (65%)]\tLoss: 0.010523\n",
      "Train Epoch: 31 [307200/392256 (78%)]\tLoss: 0.024046\n",
      "Train Epoch: 31 [358400/392256 (91%)]\tLoss: 0.013195\n",
      "test loss:0.008222355507314205\n",
      "Train Epoch: 32 [0/392256 (0%)]\tLoss: 0.008565\n",
      "Train Epoch: 32 [51200/392256 (13%)]\tLoss: 0.008989\n",
      "Train Epoch: 32 [102400/392256 (26%)]\tLoss: 0.017850\n",
      "Train Epoch: 32 [153600/392256 (39%)]\tLoss: 0.007786\n",
      "Train Epoch: 32 [204800/392256 (52%)]\tLoss: 0.013333\n",
      "Train Epoch: 32 [256000/392256 (65%)]\tLoss: 0.022198\n",
      "Train Epoch: 32 [307200/392256 (78%)]\tLoss: 0.020668\n",
      "Train Epoch: 32 [358400/392256 (91%)]\tLoss: 0.027107\n",
      "test loss:0.011185701936483383\n",
      "Train Epoch: 33 [0/392256 (0%)]\tLoss: 0.011676\n",
      "Train Epoch: 33 [51200/392256 (13%)]\tLoss: 0.017472\n",
      "Train Epoch: 33 [102400/392256 (26%)]\tLoss: 0.009243\n",
      "Train Epoch: 33 [153600/392256 (39%)]\tLoss: 0.042704\n",
      "Train Epoch: 33 [204800/392256 (52%)]\tLoss: 0.016305\n",
      "Train Epoch: 33 [256000/392256 (65%)]\tLoss: 0.013649\n",
      "Train Epoch: 33 [307200/392256 (78%)]\tLoss: 0.021503\n",
      "Train Epoch: 33 [358400/392256 (91%)]\tLoss: 0.026885\n",
      "test loss:0.03657388687133789\n",
      "Train Epoch: 34 [0/392256 (0%)]\tLoss: 0.039444\n",
      "Train Epoch: 34 [51200/392256 (13%)]\tLoss: 0.025436\n",
      "Train Epoch: 34 [102400/392256 (26%)]\tLoss: 0.021190\n",
      "Train Epoch: 34 [153600/392256 (39%)]\tLoss: 0.047031\n",
      "Train Epoch: 34 [204800/392256 (52%)]\tLoss: 0.015713\n",
      "Train Epoch: 34 [256000/392256 (65%)]\tLoss: 0.008280\n",
      "Train Epoch: 34 [307200/392256 (78%)]\tLoss: 0.015835\n",
      "Train Epoch: 34 [358400/392256 (91%)]\tLoss: 0.011420\n",
      "test loss:0.018623027950525284\n",
      "Train Epoch: 35 [0/392256 (0%)]\tLoss: 0.019681\n",
      "Train Epoch: 35 [51200/392256 (13%)]\tLoss: 0.027638\n",
      "Train Epoch: 35 [102400/392256 (26%)]\tLoss: 0.014757\n",
      "Train Epoch: 35 [153600/392256 (39%)]\tLoss: 0.010190\n",
      "Train Epoch: 35 [204800/392256 (52%)]\tLoss: 0.034875\n",
      "Train Epoch: 35 [256000/392256 (65%)]\tLoss: 0.011453\n",
      "Train Epoch: 35 [307200/392256 (78%)]\tLoss: 0.043255\n",
      "Train Epoch: 35 [358400/392256 (91%)]\tLoss: 0.031816\n",
      "test loss:0.010231681168079376\n",
      "Train Epoch: 36 [0/392256 (0%)]\tLoss: 0.009653\n",
      "Train Epoch: 36 [51200/392256 (13%)]\tLoss: 0.007946\n",
      "Train Epoch: 36 [102400/392256 (26%)]\tLoss: 0.010667\n",
      "Train Epoch: 36 [153600/392256 (39%)]\tLoss: 0.013982\n",
      "Train Epoch: 36 [204800/392256 (52%)]\tLoss: 0.023256\n",
      "Train Epoch: 36 [256000/392256 (65%)]\tLoss: 0.027109\n",
      "Train Epoch: 36 [307200/392256 (78%)]\tLoss: 0.014393\n",
      "Train Epoch: 36 [358400/392256 (91%)]\tLoss: 0.015053\n",
      "test loss:0.018117714673280716\n",
      "Train Epoch: 37 [0/392256 (0%)]\tLoss: 0.017617\n",
      "Train Epoch: 37 [51200/392256 (13%)]\tLoss: 0.011001\n",
      "Train Epoch: 37 [102400/392256 (26%)]\tLoss: 0.018771\n",
      "Train Epoch: 37 [153600/392256 (39%)]\tLoss: 0.028071\n",
      "Train Epoch: 37 [204800/392256 (52%)]\tLoss: 0.022161\n",
      "Train Epoch: 37 [256000/392256 (65%)]\tLoss: 0.020957\n",
      "Train Epoch: 37 [307200/392256 (78%)]\tLoss: 0.015386\n",
      "Train Epoch: 37 [358400/392256 (91%)]\tLoss: 0.018734\n",
      "test loss:0.016066785901784897\n",
      "Train Epoch: 38 [0/392256 (0%)]\tLoss: 0.015009\n",
      "Train Epoch: 38 [51200/392256 (13%)]\tLoss: 0.021927\n",
      "Train Epoch: 38 [102400/392256 (26%)]\tLoss: 0.028934\n",
      "Train Epoch: 38 [153600/392256 (39%)]\tLoss: 0.019179\n",
      "Train Epoch: 38 [204800/392256 (52%)]\tLoss: 0.008673\n",
      "Train Epoch: 38 [256000/392256 (65%)]\tLoss: 0.020713\n",
      "Train Epoch: 38 [307200/392256 (78%)]\tLoss: 0.015055\n",
      "Train Epoch: 38 [358400/392256 (91%)]\tLoss: 0.017340\n",
      "test loss:0.015990857034921646\n",
      "Train Epoch: 39 [0/392256 (0%)]\tLoss: 0.017119\n",
      "Train Epoch: 39 [51200/392256 (13%)]\tLoss: 0.017862\n",
      "Train Epoch: 39 [102400/392256 (26%)]\tLoss: 0.020079\n",
      "Train Epoch: 39 [153600/392256 (39%)]\tLoss: 0.009275\n",
      "Train Epoch: 39 [204800/392256 (52%)]\tLoss: 0.022286\n",
      "Train Epoch: 39 [256000/392256 (65%)]\tLoss: 0.017521\n",
      "Train Epoch: 39 [307200/392256 (78%)]\tLoss: 0.026455\n",
      "Train Epoch: 39 [358400/392256 (91%)]\tLoss: 0.020601\n",
      "test loss:0.014056900516152382\n",
      "Train Epoch: 40 [0/392256 (0%)]\tLoss: 0.012593\n",
      "Train Epoch: 40 [51200/392256 (13%)]\tLoss: 0.012234\n",
      "Train Epoch: 40 [102400/392256 (26%)]\tLoss: 0.025104\n",
      "Train Epoch: 40 [153600/392256 (39%)]\tLoss: 0.010258\n",
      "Train Epoch: 40 [204800/392256 (52%)]\tLoss: 0.017622\n",
      "Train Epoch: 40 [256000/392256 (65%)]\tLoss: 0.009079\n",
      "Train Epoch: 40 [307200/392256 (78%)]\tLoss: 0.029306\n",
      "Train Epoch: 40 [358400/392256 (91%)]\tLoss: 0.007765\n",
      "test loss:0.019490547478199005\n",
      "Train Epoch: 41 [0/392256 (0%)]\tLoss: 0.018382\n",
      "Train Epoch: 41 [51200/392256 (13%)]\tLoss: 0.015187\n",
      "Train Epoch: 41 [102400/392256 (26%)]\tLoss: 0.015870\n",
      "Train Epoch: 41 [153600/392256 (39%)]\tLoss: 0.011184\n",
      "Train Epoch: 41 [204800/392256 (52%)]\tLoss: 0.037276\n",
      "Train Epoch: 41 [256000/392256 (65%)]\tLoss: 0.015469\n",
      "Train Epoch: 41 [307200/392256 (78%)]\tLoss: 0.022254\n",
      "Train Epoch: 41 [358400/392256 (91%)]\tLoss: 0.007612\n",
      "test loss:0.027475176379084587\n",
      "Train Epoch: 42 [0/392256 (0%)]\tLoss: 0.032335\n",
      "Train Epoch: 42 [51200/392256 (13%)]\tLoss: 0.009783\n",
      "Train Epoch: 42 [102400/392256 (26%)]\tLoss: 0.035676\n",
      "Train Epoch: 42 [153600/392256 (39%)]\tLoss: 0.007211\n",
      "Train Epoch: 42 [204800/392256 (52%)]\tLoss: 0.030779\n",
      "Train Epoch: 42 [256000/392256 (65%)]\tLoss: 0.011624\n",
      "Train Epoch: 42 [307200/392256 (78%)]\tLoss: 0.014362\n",
      "Train Epoch: 42 [358400/392256 (91%)]\tLoss: 0.011746\n",
      "test loss:0.014214756898581982\n",
      "Train Epoch: 43 [0/392256 (0%)]\tLoss: 0.014268\n",
      "Train Epoch: 43 [51200/392256 (13%)]\tLoss: 0.008169\n",
      "Train Epoch: 43 [102400/392256 (26%)]\tLoss: 0.013749\n",
      "Train Epoch: 43 [153600/392256 (39%)]\tLoss: 0.015296\n",
      "Train Epoch: 43 [204800/392256 (52%)]\tLoss: 0.018423\n",
      "Train Epoch: 43 [256000/392256 (65%)]\tLoss: 0.015427\n",
      "Train Epoch: 43 [307200/392256 (78%)]\tLoss: 0.006559\n",
      "Train Epoch: 43 [358400/392256 (91%)]\tLoss: 0.016415\n",
      "test loss:0.010847597382962704\n",
      "Train Epoch: 44 [0/392256 (0%)]\tLoss: 0.010616\n",
      "Train Epoch: 44 [51200/392256 (13%)]\tLoss: 0.020701\n",
      "Train Epoch: 44 [102400/392256 (26%)]\tLoss: 0.007181\n",
      "Train Epoch: 44 [153600/392256 (39%)]\tLoss: 0.008869\n",
      "Train Epoch: 44 [204800/392256 (52%)]\tLoss: 0.024024\n",
      "Train Epoch: 44 [256000/392256 (65%)]\tLoss: 0.035849\n",
      "Train Epoch: 44 [307200/392256 (78%)]\tLoss: 0.012801\n",
      "Train Epoch: 44 [358400/392256 (91%)]\tLoss: 0.033212\n",
      "test loss:0.01207566075026989\n",
      "Train Epoch: 45 [0/392256 (0%)]\tLoss: 0.011525\n",
      "Train Epoch: 45 [51200/392256 (13%)]\tLoss: 0.026859\n",
      "Train Epoch: 45 [102400/392256 (26%)]\tLoss: 0.012238\n",
      "Train Epoch: 45 [153600/392256 (39%)]\tLoss: 0.023458\n",
      "Train Epoch: 45 [204800/392256 (52%)]\tLoss: 0.006856\n",
      "Train Epoch: 45 [256000/392256 (65%)]\tLoss: 0.024340\n",
      "Train Epoch: 45 [307200/392256 (78%)]\tLoss: 0.023384\n",
      "Train Epoch: 45 [358400/392256 (91%)]\tLoss: 0.026447\n",
      "test loss:0.00917254202067852\n",
      "Train Epoch: 46 [0/392256 (0%)]\tLoss: 0.009706\n",
      "Train Epoch: 46 [51200/392256 (13%)]\tLoss: 0.009098\n",
      "Train Epoch: 46 [102400/392256 (26%)]\tLoss: 0.008105\n",
      "Train Epoch: 46 [153600/392256 (39%)]\tLoss: 0.021778\n",
      "Train Epoch: 46 [204800/392256 (52%)]\tLoss: 0.024861\n",
      "Train Epoch: 46 [256000/392256 (65%)]\tLoss: 0.011941\n",
      "Train Epoch: 46 [307200/392256 (78%)]\tLoss: 0.022382\n",
      "Train Epoch: 46 [358400/392256 (91%)]\tLoss: 0.022046\n",
      "test loss:0.02809017524123192\n",
      "Train Epoch: 47 [0/392256 (0%)]\tLoss: 0.024340\n",
      "Train Epoch: 47 [51200/392256 (13%)]\tLoss: 0.012313\n",
      "Train Epoch: 47 [102400/392256 (26%)]\tLoss: 0.010101\n",
      "Train Epoch: 47 [153600/392256 (39%)]\tLoss: 0.013806\n",
      "Train Epoch: 47 [204800/392256 (52%)]\tLoss: 0.022941\n",
      "Train Epoch: 47 [256000/392256 (65%)]\tLoss: 0.016133\n",
      "Train Epoch: 47 [307200/392256 (78%)]\tLoss: 0.008072\n",
      "Train Epoch: 47 [358400/392256 (91%)]\tLoss: 0.025601\n",
      "test loss:0.012535110116004944\n",
      "Train Epoch: 48 [0/392256 (0%)]\tLoss: 0.011706\n",
      "Train Epoch: 48 [51200/392256 (13%)]\tLoss: 0.020310\n",
      "Train Epoch: 48 [102400/392256 (26%)]\tLoss: 0.014455\n",
      "Train Epoch: 48 [153600/392256 (39%)]\tLoss: 0.007989\n",
      "Train Epoch: 48 [204800/392256 (52%)]\tLoss: 0.010024\n",
      "Train Epoch: 48 [256000/392256 (65%)]\tLoss: 0.026349\n",
      "Train Epoch: 48 [307200/392256 (78%)]\tLoss: 0.014955\n",
      "Train Epoch: 48 [358400/392256 (91%)]\tLoss: 0.021429\n",
      "test loss:0.03392009437084198\n",
      "Train Epoch: 49 [0/392256 (0%)]\tLoss: 0.038595\n",
      "Train Epoch: 49 [51200/392256 (13%)]\tLoss: 0.009225\n",
      "Train Epoch: 49 [102400/392256 (26%)]\tLoss: 0.007299\n",
      "Train Epoch: 49 [153600/392256 (39%)]\tLoss: 0.032258\n",
      "Train Epoch: 49 [204800/392256 (52%)]\tLoss: 0.029213\n",
      "Train Epoch: 49 [256000/392256 (65%)]\tLoss: 0.018586\n",
      "Train Epoch: 49 [307200/392256 (78%)]\tLoss: 0.011242\n",
      "Train Epoch: 49 [358400/392256 (91%)]\tLoss: 0.030035\n",
      "test loss:0.017218895256519318\n",
      "Train Epoch: 50 [0/392256 (0%)]\tLoss: 0.015648\n",
      "Train Epoch: 50 [51200/392256 (13%)]\tLoss: 0.007101\n",
      "Train Epoch: 50 [102400/392256 (26%)]\tLoss: 0.006343\n",
      "Train Epoch: 50 [153600/392256 (39%)]\tLoss: 0.023912\n",
      "Train Epoch: 50 [204800/392256 (52%)]\tLoss: 0.012052\n",
      "Train Epoch: 50 [256000/392256 (65%)]\tLoss: 0.006595\n",
      "Train Epoch: 50 [307200/392256 (78%)]\tLoss: 0.019571\n",
      "Train Epoch: 50 [358400/392256 (91%)]\tLoss: 0.015776\n",
      "test loss:0.011785119771957397\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "best_loss = 1\n",
    "\n",
    "for epoch in range(1, 50 + 1):\n",
    "    train(model, device, train_dataloader, optimizer, epoch)\n",
    "    best_loss = test(model, device, test_dataloader, optimizer, epoch, best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('SDF.torch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0132]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model = model.eval()\n",
    "model(torch.from_numpy(np.array([2.3454492 , -0.96645486,  8.859472])).unsqueeze(0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(SDFs):\n",
    "    if x<-0.2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0081353"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SDFs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.3454492 , -0.96645486,  8.859472  ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
