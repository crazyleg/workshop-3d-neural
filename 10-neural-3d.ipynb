{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb, math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pdb\n",
    "import cv2\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "modules=list(resnet18.children())[:-1]\n",
    "resnet18=nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SDF, self).__init__()\n",
    "        self.fc1 = nn.Linear(1003, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 512)     \n",
    "        self.fc6 = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         pdb.set_trace()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "sdf_model = SDF()\n",
    "# sdf_model.load_state_dict(torch.load('sdf.torch'))\n",
    "sdf_model = sdf_model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(sdf_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SDFDataset(Dataset):\n",
    "\n",
    "    def __init__(self,folder):\n",
    "        self.folder = folder\n",
    "        self.files = os.listdir(folder)\n",
    "#         pdb.set_trace()\n",
    "        self.unique_ids = [x[0].split('_')[0] for x in self.files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print()\n",
    "        pr1 = cv2.imread(self.folder+self.unique_ids[int(idx)]+'_-1.png', cv2.IMREAD_GRAYSCALE)\n",
    "        pr2 = cv2.imread(self.folder+self.unique_ids[int(idx)]+'_0.png', cv2.IMREAD_GRAYSCALE)\n",
    "        pr3 = cv2.imread(self.folder+self.unique_ids[int(idx)]+'_1.png', cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        result = torch.from_numpy(np.stack([pr1,pr2,pr3])).float()/255\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    return torch.stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from torch.utils import data\n",
    "dataset = SDFDataset('/home/alex/data/3d/')\n",
    "\n",
    "idx = dataset.unique_ids\n",
    "random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
    "train_idx = idx[:int(len(idx)*0.8)]\n",
    "test_idx = idx[int(len(idx)*0.8):]\n",
    "\n",
    "train_set = data.Subset(dataset, train_idx)\n",
    "test_set = data.Subset(dataset, test_idx)\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=16,\n",
    "                        shuffle=True, num_workers=1)\n",
    "test_dataloader = DataLoader(test_set, batch_size=16,\n",
    "                        shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ORIGIN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-41fac3bdedf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# origin is at -5, getector is at 5 placing objects in the middle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetectorSquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mORIGIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_image_with_SDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ORIGIN' is not defined"
     ]
    }
   ],
   "source": [
    "class DetectorSquare():\n",
    "    def __init__(self, origin, h=100, w=120, z=0):\n",
    "        self.h, self.w = h, w\n",
    "        self.r = float(self.w) / self.h\n",
    "        self.x1, self.x2, self.y1, self.y2, self.z1, self.z2 = -1, 1, -1. / self.r + .25, 1. / self.r + .25, z, -z\n",
    "        self.xes = np.linspace(self.x1, self.x2, self.w)\n",
    "        self.yes = np.linspace(self.y1, self.y2, self.h)\n",
    "\n",
    "# origin is at -5, getector is at 5 placing objects in the middle        \n",
    "detector = DetectorSquare(ORIGIN, h=H, w=W, z=5)\n",
    "\n",
    "def get_image_with_SDF(vector, angle):\n",
    "    current_points = ORIGIN.repeat(detector.w,1).view(detector.w,3).repeat(detector.h,1).view(detector.h,detector.w,3).permute(2,1,0).float().to('cuda')\n",
    "\n",
    "    energy_map = torch.from_numpy(np.zeros((detector.w,detector.h))).float().to('cuda')\n",
    "    range_map = torch.from_numpy(np.zeros((detector.w,detector.h))).float().to('cuda')\n",
    "\n",
    "    INNER_STEP_TORCH = torch.tensor(INNER_STEP).to('cuda')\n",
    "    vector_normals = (vectors.float() / norm(vectors.float())).to('cuda')\n",
    "    ORIGIN_TORCH = ORIGIN.float()[:,None,None] .to('cuda')\n",
    "    TORCH_ZERO = torch.tensor(0.).to('cuda')\n",
    "    TORCH_ONE = torch.tensor(1.).to('cuda')\n",
    "\n",
    "    #unit vectors from origin to detector plane\n",
    "    vectors = rays - torch.from_numpy(ORIGIN.numpy()[:,None,None]).float().to('cuda')\n",
    "    #starting positions over every vector\n",
    "    current_points = ORIGIN.repeat(detector.w,1).view(detector.w,3).repeat(detector.h,1).view(detector.h,detector.w,3).permute(2,1,0).float()\n",
    "    #placeholders\n",
    "    energy_map = torch.from_numpy(np.zeros((detector.w,detector.h))).float().to('cuda')\n",
    "    range_map = torch.from_numpy(np.zeros((detector.w,detector.h))).float().to('cuda')\n",
    "    INNER_STEP_TORCH = torch.tensor(INNER_STEP).to('cuda')\n",
    "    vector_normals = (vectors.float() / norm(vectors.float())).to('cuda')\n",
    "    ORIGIN_TORCH = ORIGIN.float()[:,None,None] .to('cuda')\n",
    "    for i in range(10):\n",
    "        min_distance = scene.trace(current_points, angle) \n",
    "        min_distance = torch.where(min_distance>EPSILON, min_distance.float(), INNER_STEP_TORCH)\n",
    "        current_points = torch_displance_point_along_vector(ORIGIN_TORCH, \n",
    "                                                            vector_normals, \n",
    "                                                            range_map.float().view(256,1)+min_distance.float()) \n",
    "\n",
    "        range_map  += min_distance\n",
    "        energy_map += torch.where(min_distance>EPSILON, TORCH_ZERO, TORCH_ONE)\n",
    "        if min_distance.min()>10: break\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scene():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        \n",
    "    def trace(self, points, angle, latent_vector):\n",
    "        angle = rotation_matrix([0,0,1],angle)\n",
    "        \n",
    "        points = points.view(3,256)\n",
    "        #FIX EINSUM\n",
    "        \n",
    "        #POINT OF ERROR - CHECK ME\n",
    "        points = torch.einsum('iq,ij->qj',torch.from_numpy(angle).float().to('cuda'),points.to('cuda')).to('cuda')\n",
    "#         pdb.set_trace()\n",
    "        # latent_vector repeat 16\n",
    "        # torch.cat() \n",
    "        \n",
    "        return self.model(torch.cat([points.permute(1,0),latent_vector.repeat(16,1)], dim=1)).view(-1,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = Scene(sdf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(vectors): return torch.sqrt((vectors).pow(2).sum(0))\n",
    "\n",
    "def torch_displace_point_along_vector(rays0, vectors, distances):\n",
    "#     pdb.set_trace()\n",
    "    return rays0 + (vectors.permute(1,0).repeat(16,1) * distances.float()).permute(1,0).view(3,16,16)\n",
    "\n",
    "def trace_me(latent_vector):\n",
    "    with torch.autograd.set_grad_enabled(True):\n",
    "        ORIGIN = torch.tensor(np.array([0.,0.,-5.]), requires_grad=True)\n",
    "        EPSILON = 0.01\n",
    "        INNER_STEP = .01\n",
    "\n",
    "        detector_points = torch.randint(0, 280, (16,2))\n",
    "        current_points = ORIGIN.repeat(16,1).view(16,3).repeat(16,1).view(16,16,3).permute(2,1,0).float()\n",
    "\n",
    "        energy_map = torch.zeros((16,16), requires_grad=True).float().to('cuda')\n",
    "#         pdb.set_trace()\n",
    "        range_map = torch.zeros((16,16), requires_grad=True).float().to('cuda')\n",
    "\n",
    "        ORIGIN_TORCH = ORIGIN.float()[:,None,None].to('cuda')\n",
    "        TORCH_ZERO = torch.tensor(0., requires_grad=True).to('cuda')\n",
    "        TORCH_ONE = torch.tensor(1., requires_grad=True).to('cuda')\n",
    "        INNER_STEP_TORCH = torch.tensor(INNER_STEP, requires_grad=True).to('cuda')\n",
    "\n",
    "        rays = torch.cat([((detector_points+10).float()/150-1),torch.zeros(16,1)], dim=1).permute(1,0).to('cuda')\n",
    "        vectors = rays - ORIGIN[:,None].float().to('cuda')\n",
    "\n",
    "        INNER_STEP_TORCH = torch.tensor(INNER_STEP).to('cuda')\n",
    "        vector_normals = (vectors.float() / norm(vectors.float())).to('cuda')\n",
    "        ORIGIN_TORCH = ORIGIN.float()[:,None,None] .to('cuda')\n",
    "\n",
    "        for i in range(10):\n",
    "\n",
    "            min_distance = scene.trace(current_points.to('cuda'), torch.tensor(0).to('cuda'), latent_vector) *10\n",
    "#             print(min_distance.mean())\n",
    "            min_distance = torch.where(min_distance>EPSILON, min_distance.float(), INNER_STEP_TORCH)\n",
    "        #     min_distance = torch.where(min_distance>100, min_distance.float(), torch.tensor(100))\n",
    "    #         pdb.set_trace()\n",
    "    #         print(current_points[:,5,5])\n",
    "            current_points = torch_displace_point_along_vector(ORIGIN_TORCH, vector_normals, range_map.float().view(256,1)+min_distance.float()) \n",
    "    #         pdb.set_trace()\n",
    "            range_map  += min_distance.view(16,16)\n",
    "    #         pdb.set_trace()\n",
    "#             pdb.set_trace()    \n",
    "            energy_map += torch.where(min_distance>EPSILON, TORCH_ZERO, TORCH_ONE).view(16,16)\n",
    "            if min_distance.min()>10: break\n",
    "        return energy_map, detector_points\n",
    "            \n",
    "# ORIGIN_TORCH torch.Size([3, 1, 1])\n",
    "# vector_normals torch.Size([3, 16])\n",
    "# range_map torch.Size([16, 16])\n",
    "# min_distance.float() torch.Size([256, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    sdf_model.train()\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        data = sample.to(device)\n",
    "\n",
    "        output = model(data)    \n",
    "        energy_map, detection_points = trace_me(output.to('cuda'))\n",
    "        print(energy_map.mean())\n",
    "        loss = []\n",
    "        for i in range(16):\n",
    "            for j in range(16):\n",
    "#                 pdb.set_trace()\n",
    "#                 print(data[i,1,detection_points[j,0],detection_points[j,1]]*255)\n",
    "                loss.append(F.l1_loss(energy_map[i,j],data[i,1,detection_points[j,0],detection_points[j,1]]*255))\n",
    "#         pdb.set_trace()\n",
    "#         print(energy_map)\n",
    "        loss = torch.stack(loss).mean()\n",
    "        loss.backward()\n",
    "#         pdb.set_trace()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, device, test_loader, optimizer, epoch, best_loss=1):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for batch_idx, sample in enumerate(test_loader):\n",
    "        data, target = sample['coords'].to(device), sample['sdf'].to(device)\n",
    "        output = model(data)\n",
    "        #SDF here\n",
    "        for i in output.shape[0]:\n",
    "            #comapre to random angle out of 3\n",
    "            image = get_image_with_SDF(output[i], angle = 0)\n",
    "            \n",
    "        loss = F.l1_loss(output, target)\n",
    "        losses.append(loss)\n",
    "#     pdb.set_trace()\n",
    "    loss = sum(losses)/len(losses)\n",
    "    print(f'test loss:{loss}')\n",
    "    if loss<best_loss:\n",
    "        torch.save(model.state_dict(), 'sdf.torch')\n",
    "        best_loss = loss\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (256) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-64be40d85161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#     best_loss = test(model, device, test_dataloader, optimizer, epoch, best_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-160-ff3062baf85c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0menergy_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-159-43520ec1f72f>\u001b[0m in \u001b[0;36mtrace_me\u001b[0;34m(latent_vector)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#         pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#         print(current_points[:,5,5])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mcurrent_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_displace_point_along_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mORIGIN_TORCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_normals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmin_distance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m#         pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mrange_map\u001b[0m  \u001b[0;34m+=\u001b[0m \u001b[0mmin_distance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-159-43520ec1f72f>\u001b[0m in \u001b[0;36mtorch_displace_point_along_vector\u001b[0;34m(rays0, vectors, distances)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtorch_displace_point_along_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrays0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrays0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrace_me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (256) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "best_loss = 1\n",
    "\n",
    "for epoch in range(1, 50 + 1):\n",
    "    train(model_ft, device, train_dataloader, optimizer_ft, epoch)\n",
    "#     best_loss = test(model, device, test_dataloader, optimizer, epoch, best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.load_state_dict(torch.load('SDF.torch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0132]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model = model.eval()\n",
    "model(torch.from_numpy(np.array([2.3454492 , -0.96645486,  8.859472])).unsqueeze(0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(SDFs):\n",
    "    if x<-0.2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0081353"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SDFs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.3454492 , -0.96645486,  8.859472  ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
