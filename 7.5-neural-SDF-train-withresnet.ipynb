{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb, math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pdb\n",
    "import torch.nn as nn\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SDF, self).__init__()\n",
    "        self.fc1 = nn.Linear(515, 512)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 512)     \n",
    "        self.fc6 = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         pdb.set_trace()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# coords = np.load('coords.npy')\n",
    "# SDFs = np.load('SDF.npy')\n",
    "\n",
    "coords = [np.load(f'/home/alex/data/3dc/{x}coords.npy') for x in range(100)]\n",
    "SDFs = [np.load(f'/home/alex/data/3dc/{x}SDF.npy') for x in range(100)]\n",
    "\n",
    "coords = np.concatenate(coords)\n",
    "SDFs = np.concatenate(SDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idxes = [i for i, s in enumerate(SDFs) if s<20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SDFDataset(Dataset):\n",
    "\n",
    "    def __init__(self,coords,SDFs):\n",
    "        self.coords = coords\n",
    "        self.SDFs = SDFs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.SDFs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        coord = torch.from_numpy(self.coords[idx])\n",
    "        sdf = torch.from_numpy(np.array(self.SDFs[idx])).unsqueeze(0)\n",
    "\n",
    "#         pdb.set_trace()\n",
    "        sample = {'coords': coord, 'sdf': sdf}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils import data\n",
    "dataset = SDFDataset(coords,SDFs)\n",
    "\n",
    "idx = list(range(len(coords)))\n",
    "random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
    "train_idx = idx[:int(len(coords)*0.8)]\n",
    "test_idx = idx[int(len(coords)*0.8):]\n",
    "\n",
    "train_set = data.Subset(dataset, train_idx)\n",
    "test_set = data.Subset(dataset, test_idx)\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=256,\n",
    "                        shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_set, batch_size=256,\n",
    "                        shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "#         pdb.set_trace()\n",
    "        data, target = sample['coords'].to(device), sample['sdf'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "        loss = F.l1_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, device, test_loader, optimizer, epoch, best_loss=1):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, sample in enumerate(test_loader):\n",
    "            data, target = sample['coords'].to(device), sample['sdf'].to(device)\n",
    "            output = model(data)\n",
    "            loss = F.l1_loss(output, target)\n",
    "            losses.append(loss)\n",
    "    #     pdb.set_trace()\n",
    "        loss = sum(losses)/len(losses)\n",
    "        print(f'test loss:{loss}')\n",
    "        if loss<best_loss:\n",
    "            torch.save(model.state_dict(), 'sdf_with_latent.torch')\n",
    "            best_loss = loss\n",
    "        return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = SDF().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1561122 (0%)]\tLoss: 5.439217\n",
      "Train Epoch: 1 [256000/1561122 (16%)]\tLoss: 0.347641\n",
      "Train Epoch: 1 [512000/1561122 (33%)]\tLoss: 0.236828\n",
      "Train Epoch: 1 [768000/1561122 (49%)]\tLoss: 0.130061\n",
      "Train Epoch: 1 [1024000/1561122 (66%)]\tLoss: 0.127078\n",
      "Train Epoch: 1 [1280000/1561122 (82%)]\tLoss: 0.108003\n",
      "Train Epoch: 1 [1536000/1561122 (98%)]\tLoss: 0.095373\n",
      "test loss:0.12245526164770126\n",
      "Train Epoch: 2 [0/1561122 (0%)]\tLoss: 0.121494\n",
      "Train Epoch: 2 [256000/1561122 (16%)]\tLoss: 0.088297\n",
      "Train Epoch: 2 [512000/1561122 (33%)]\tLoss: 0.093667\n",
      "Train Epoch: 2 [768000/1561122 (49%)]\tLoss: 0.088872\n",
      "Train Epoch: 2 [1024000/1561122 (66%)]\tLoss: 0.082109\n",
      "Train Epoch: 2 [1280000/1561122 (82%)]\tLoss: 0.088363\n",
      "Train Epoch: 2 [1536000/1561122 (98%)]\tLoss: 0.085791\n",
      "test loss:0.08147022873163223\n",
      "Train Epoch: 3 [0/1561122 (0%)]\tLoss: 0.069396\n",
      "Train Epoch: 3 [256000/1561122 (16%)]\tLoss: 0.074865\n",
      "Train Epoch: 3 [512000/1561122 (33%)]\tLoss: 0.084982\n",
      "Train Epoch: 3 [768000/1561122 (49%)]\tLoss: 0.078468\n",
      "Train Epoch: 3 [1024000/1561122 (66%)]\tLoss: 0.075082\n",
      "Train Epoch: 3 [1280000/1561122 (82%)]\tLoss: 0.077953\n",
      "Train Epoch: 3 [1536000/1561122 (98%)]\tLoss: 0.082122\n",
      "test loss:0.07536381483078003\n",
      "Train Epoch: 4 [0/1561122 (0%)]\tLoss: 0.068690\n",
      "Train Epoch: 4 [256000/1561122 (16%)]\tLoss: 0.078251\n",
      "Train Epoch: 4 [512000/1561122 (33%)]\tLoss: 0.076020\n",
      "Train Epoch: 4 [768000/1561122 (49%)]\tLoss: 0.076192\n",
      "Train Epoch: 4 [1024000/1561122 (66%)]\tLoss: 0.065999\n",
      "Train Epoch: 4 [1280000/1561122 (82%)]\tLoss: 0.075618\n",
      "Train Epoch: 4 [1536000/1561122 (98%)]\tLoss: 0.069972\n",
      "test loss:0.07955051958560944\n",
      "Train Epoch: 5 [0/1561122 (0%)]\tLoss: 0.081281\n",
      "Train Epoch: 5 [256000/1561122 (16%)]\tLoss: 0.064872\n",
      "Train Epoch: 5 [512000/1561122 (33%)]\tLoss: 0.084969\n",
      "Train Epoch: 5 [768000/1561122 (49%)]\tLoss: 0.066909\n",
      "Train Epoch: 5 [1024000/1561122 (66%)]\tLoss: 0.063222\n",
      "Train Epoch: 5 [1280000/1561122 (82%)]\tLoss: 0.072834\n",
      "Train Epoch: 5 [1536000/1561122 (98%)]\tLoss: 0.069637\n",
      "test loss:0.0708349198102951\n",
      "Train Epoch: 6 [0/1561122 (0%)]\tLoss: 0.070153\n",
      "Train Epoch: 6 [256000/1561122 (16%)]\tLoss: 0.069462\n",
      "Train Epoch: 6 [512000/1561122 (33%)]\tLoss: 0.067809\n",
      "Train Epoch: 6 [768000/1561122 (49%)]\tLoss: 0.070045\n",
      "Train Epoch: 6 [1024000/1561122 (66%)]\tLoss: 0.072168\n",
      "Train Epoch: 6 [1280000/1561122 (82%)]\tLoss: 0.070200\n",
      "Train Epoch: 6 [1536000/1561122 (98%)]\tLoss: 0.064743\n",
      "test loss:0.06744641065597534\n",
      "Train Epoch: 7 [0/1561122 (0%)]\tLoss: 0.065946\n",
      "Train Epoch: 7 [256000/1561122 (16%)]\tLoss: 0.068610\n",
      "Train Epoch: 7 [512000/1561122 (33%)]\tLoss: 0.071142\n",
      "Train Epoch: 7 [768000/1561122 (49%)]\tLoss: 0.073110\n",
      "Train Epoch: 7 [1024000/1561122 (66%)]\tLoss: 0.066248\n",
      "Train Epoch: 7 [1280000/1561122 (82%)]\tLoss: 0.056914\n",
      "Train Epoch: 7 [1536000/1561122 (98%)]\tLoss: 0.071006\n",
      "test loss:0.06239710748195648\n",
      "Train Epoch: 8 [0/1561122 (0%)]\tLoss: 0.064512\n",
      "Train Epoch: 8 [256000/1561122 (16%)]\tLoss: 0.062572\n",
      "Train Epoch: 8 [512000/1561122 (33%)]\tLoss: 0.064292\n",
      "Train Epoch: 8 [768000/1561122 (49%)]\tLoss: 0.066284\n",
      "Train Epoch: 8 [1024000/1561122 (66%)]\tLoss: 0.066731\n",
      "Train Epoch: 8 [1280000/1561122 (82%)]\tLoss: 0.061125\n",
      "Train Epoch: 8 [1536000/1561122 (98%)]\tLoss: 0.064656\n",
      "test loss:0.06821983307600021\n",
      "Train Epoch: 9 [0/1561122 (0%)]\tLoss: 0.070735\n",
      "Train Epoch: 9 [256000/1561122 (16%)]\tLoss: 0.061868\n",
      "Train Epoch: 9 [512000/1561122 (33%)]\tLoss: 0.062231\n",
      "Train Epoch: 9 [768000/1561122 (49%)]\tLoss: 0.061198\n",
      "Train Epoch: 9 [1024000/1561122 (66%)]\tLoss: 0.062150\n",
      "Train Epoch: 9 [1280000/1561122 (82%)]\tLoss: 0.059590\n",
      "Train Epoch: 9 [1536000/1561122 (98%)]\tLoss: 0.060828\n",
      "test loss:0.0625864639878273\n",
      "Train Epoch: 10 [0/1561122 (0%)]\tLoss: 0.059449\n",
      "Train Epoch: 10 [256000/1561122 (16%)]\tLoss: 0.060170\n",
      "Train Epoch: 10 [512000/1561122 (33%)]\tLoss: 0.064282\n",
      "Train Epoch: 10 [768000/1561122 (49%)]\tLoss: 0.064172\n",
      "Train Epoch: 10 [1024000/1561122 (66%)]\tLoss: 0.057347\n",
      "Train Epoch: 10 [1280000/1561122 (82%)]\tLoss: 0.057680\n",
      "Train Epoch: 10 [1536000/1561122 (98%)]\tLoss: 0.056111\n",
      "test loss:0.07017476111650467\n",
      "Train Epoch: 11 [0/1561122 (0%)]\tLoss: 0.072331\n",
      "Train Epoch: 11 [256000/1561122 (16%)]\tLoss: 0.058573\n",
      "Train Epoch: 11 [512000/1561122 (33%)]\tLoss: 0.058952\n",
      "Train Epoch: 11 [768000/1561122 (49%)]\tLoss: 0.057862\n",
      "Train Epoch: 11 [1024000/1561122 (66%)]\tLoss: 0.053496\n",
      "Train Epoch: 11 [1280000/1561122 (82%)]\tLoss: 0.053200\n",
      "Train Epoch: 11 [1536000/1561122 (98%)]\tLoss: 0.060534\n",
      "test loss:0.058701928704977036\n",
      "Train Epoch: 12 [0/1561122 (0%)]\tLoss: 0.069550\n",
      "Train Epoch: 12 [256000/1561122 (16%)]\tLoss: 0.056310\n",
      "Train Epoch: 12 [512000/1561122 (33%)]\tLoss: 0.051475\n",
      "Train Epoch: 12 [768000/1561122 (49%)]\tLoss: 0.061608\n",
      "Train Epoch: 12 [1024000/1561122 (66%)]\tLoss: 0.056857\n",
      "Train Epoch: 12 [1280000/1561122 (82%)]\tLoss: 0.052073\n",
      "Train Epoch: 12 [1536000/1561122 (98%)]\tLoss: 0.054355\n",
      "test loss:0.0590275414288044\n",
      "Train Epoch: 13 [0/1561122 (0%)]\tLoss: 0.055197\n",
      "Train Epoch: 13 [256000/1561122 (16%)]\tLoss: 0.060310\n",
      "Train Epoch: 13 [512000/1561122 (33%)]\tLoss: 0.062093\n",
      "Train Epoch: 13 [768000/1561122 (49%)]\tLoss: 0.069270\n",
      "Train Epoch: 13 [1024000/1561122 (66%)]\tLoss: 0.062242\n",
      "Train Epoch: 13 [1280000/1561122 (82%)]\tLoss: 0.056173\n",
      "Train Epoch: 13 [1536000/1561122 (98%)]\tLoss: 0.055706\n",
      "test loss:0.06042107194662094\n",
      "Train Epoch: 14 [0/1561122 (0%)]\tLoss: 0.058711\n",
      "Train Epoch: 14 [256000/1561122 (16%)]\tLoss: 0.070351\n",
      "Train Epoch: 14 [512000/1561122 (33%)]\tLoss: 0.061693\n",
      "Train Epoch: 14 [768000/1561122 (49%)]\tLoss: 0.052286\n",
      "Train Epoch: 14 [1024000/1561122 (66%)]\tLoss: 0.053008\n",
      "Train Epoch: 14 [1280000/1561122 (82%)]\tLoss: 0.057991\n",
      "Train Epoch: 14 [1536000/1561122 (98%)]\tLoss: 0.056492\n",
      "test loss:0.05598435178399086\n",
      "Train Epoch: 15 [0/1561122 (0%)]\tLoss: 0.058515\n",
      "Train Epoch: 15 [256000/1561122 (16%)]\tLoss: 0.053512\n",
      "Train Epoch: 15 [512000/1561122 (33%)]\tLoss: 0.058590\n",
      "Train Epoch: 15 [768000/1561122 (49%)]\tLoss: 0.061164\n",
      "Train Epoch: 15 [1024000/1561122 (66%)]\tLoss: 0.063525\n",
      "Train Epoch: 15 [1280000/1561122 (82%)]\tLoss: 0.051117\n",
      "Train Epoch: 15 [1536000/1561122 (98%)]\tLoss: 0.067256\n",
      "test loss:0.06278245151042938\n",
      "Train Epoch: 16 [0/1561122 (0%)]\tLoss: 0.063594\n",
      "Train Epoch: 16 [256000/1561122 (16%)]\tLoss: 0.059742\n",
      "Train Epoch: 16 [512000/1561122 (33%)]\tLoss: 0.049596\n",
      "Train Epoch: 16 [768000/1561122 (49%)]\tLoss: 0.057970\n",
      "Train Epoch: 16 [1024000/1561122 (66%)]\tLoss: 0.060686\n",
      "Train Epoch: 16 [1280000/1561122 (82%)]\tLoss: 0.048357\n",
      "Train Epoch: 16 [1536000/1561122 (98%)]\tLoss: 0.051245\n",
      "test loss:0.05799126625061035\n",
      "Train Epoch: 17 [0/1561122 (0%)]\tLoss: 0.059419\n",
      "Train Epoch: 17 [256000/1561122 (16%)]\tLoss: 0.051700\n",
      "Train Epoch: 17 [512000/1561122 (33%)]\tLoss: 0.056000\n",
      "Train Epoch: 17 [768000/1561122 (49%)]\tLoss: 0.052709\n",
      "Train Epoch: 17 [1024000/1561122 (66%)]\tLoss: 0.054433\n",
      "Train Epoch: 17 [1280000/1561122 (82%)]\tLoss: 0.054761\n",
      "Train Epoch: 17 [1536000/1561122 (98%)]\tLoss: 0.058374\n",
      "test loss:0.05373205989599228\n",
      "Train Epoch: 18 [0/1561122 (0%)]\tLoss: 0.052128\n",
      "Train Epoch: 18 [256000/1561122 (16%)]\tLoss: 0.054003\n",
      "Train Epoch: 18 [512000/1561122 (33%)]\tLoss: 0.049335\n",
      "Train Epoch: 18 [768000/1561122 (49%)]\tLoss: 0.060683\n",
      "Train Epoch: 18 [1024000/1561122 (66%)]\tLoss: 0.054070\n",
      "Train Epoch: 18 [1280000/1561122 (82%)]\tLoss: 0.050904\n",
      "Train Epoch: 18 [1536000/1561122 (98%)]\tLoss: 0.055952\n",
      "test loss:0.06961788237094879\n",
      "Train Epoch: 19 [0/1561122 (0%)]\tLoss: 0.069622\n",
      "Train Epoch: 19 [256000/1561122 (16%)]\tLoss: 0.057111\n",
      "Train Epoch: 19 [512000/1561122 (33%)]\tLoss: 0.049117\n",
      "Train Epoch: 19 [768000/1561122 (49%)]\tLoss: 0.049650\n",
      "Train Epoch: 19 [1024000/1561122 (66%)]\tLoss: 0.047353\n",
      "Train Epoch: 19 [1280000/1561122 (82%)]\tLoss: 0.054141\n",
      "Train Epoch: 19 [1536000/1561122 (98%)]\tLoss: 0.049564\n",
      "test loss:0.050032082945108414\n",
      "Train Epoch: 20 [0/1561122 (0%)]\tLoss: 0.047220\n",
      "Train Epoch: 20 [256000/1561122 (16%)]\tLoss: 0.057244\n",
      "Train Epoch: 20 [512000/1561122 (33%)]\tLoss: 0.046390\n",
      "Train Epoch: 20 [768000/1561122 (49%)]\tLoss: 0.056309\n",
      "Train Epoch: 20 [1024000/1561122 (66%)]\tLoss: 0.051424\n",
      "Train Epoch: 20 [1280000/1561122 (82%)]\tLoss: 0.053181\n",
      "Train Epoch: 20 [1536000/1561122 (98%)]\tLoss: 0.049946\n",
      "test loss:0.05630405992269516\n",
      "Train Epoch: 21 [0/1561122 (0%)]\tLoss: 0.052862\n",
      "Train Epoch: 21 [256000/1561122 (16%)]\tLoss: 0.053396\n",
      "Train Epoch: 21 [512000/1561122 (33%)]\tLoss: 0.053135\n",
      "Train Epoch: 21 [768000/1561122 (49%)]\tLoss: 0.056116\n",
      "Train Epoch: 21 [1024000/1561122 (66%)]\tLoss: 0.048449\n",
      "Train Epoch: 21 [1280000/1561122 (82%)]\tLoss: 0.049550\n",
      "Train Epoch: 21 [1536000/1561122 (98%)]\tLoss: 0.054457\n",
      "test loss:0.05122918635606766\n",
      "Train Epoch: 22 [0/1561122 (0%)]\tLoss: 0.049744\n",
      "Train Epoch: 22 [256000/1561122 (16%)]\tLoss: 0.049988\n",
      "Train Epoch: 22 [512000/1561122 (33%)]\tLoss: 0.064175\n",
      "Train Epoch: 22 [768000/1561122 (49%)]\tLoss: 0.047825\n",
      "Train Epoch: 22 [1024000/1561122 (66%)]\tLoss: 0.053338\n",
      "Train Epoch: 22 [1280000/1561122 (82%)]\tLoss: 0.050023\n",
      "Train Epoch: 22 [1536000/1561122 (98%)]\tLoss: 0.046209\n",
      "test loss:0.06993917375802994\n",
      "Train Epoch: 23 [0/1561122 (0%)]\tLoss: 0.071789\n",
      "Train Epoch: 23 [256000/1561122 (16%)]\tLoss: 0.057605\n",
      "Train Epoch: 23 [512000/1561122 (33%)]\tLoss: 0.055179\n",
      "Train Epoch: 23 [768000/1561122 (49%)]\tLoss: 0.053051\n",
      "Train Epoch: 23 [1024000/1561122 (66%)]\tLoss: 0.050371\n",
      "Train Epoch: 23 [1280000/1561122 (82%)]\tLoss: 0.055169\n",
      "Train Epoch: 23 [1536000/1561122 (98%)]\tLoss: 0.048102\n",
      "test loss:0.04996902868151665\n",
      "Train Epoch: 24 [0/1561122 (0%)]\tLoss: 0.048304\n",
      "Train Epoch: 24 [256000/1561122 (16%)]\tLoss: 0.056474\n",
      "Train Epoch: 24 [512000/1561122 (33%)]\tLoss: 0.053756\n",
      "Train Epoch: 24 [768000/1561122 (49%)]\tLoss: 0.064218\n",
      "Train Epoch: 24 [1024000/1561122 (66%)]\tLoss: 0.044586\n",
      "Train Epoch: 24 [1280000/1561122 (82%)]\tLoss: 0.054238\n",
      "Train Epoch: 24 [1536000/1561122 (98%)]\tLoss: 0.051229\n",
      "test loss:0.05040654540061951\n",
      "Train Epoch: 25 [0/1561122 (0%)]\tLoss: 0.048873\n",
      "Train Epoch: 25 [256000/1561122 (16%)]\tLoss: 0.046639\n",
      "Train Epoch: 25 [512000/1561122 (33%)]\tLoss: 0.052083\n",
      "Train Epoch: 25 [768000/1561122 (49%)]\tLoss: 0.055549\n",
      "Train Epoch: 25 [1024000/1561122 (66%)]\tLoss: 0.048978\n",
      "Train Epoch: 25 [1280000/1561122 (82%)]\tLoss: 0.060463\n",
      "Train Epoch: 25 [1536000/1561122 (98%)]\tLoss: 0.049540\n",
      "test loss:0.05117694288492203\n",
      "Train Epoch: 26 [0/1561122 (0%)]\tLoss: 0.052584\n",
      "Train Epoch: 26 [256000/1561122 (16%)]\tLoss: 0.051836\n",
      "Train Epoch: 26 [512000/1561122 (33%)]\tLoss: 0.049766\n",
      "Train Epoch: 26 [768000/1561122 (49%)]\tLoss: 0.051872\n",
      "Train Epoch: 26 [1024000/1561122 (66%)]\tLoss: 0.045219\n",
      "Train Epoch: 26 [1280000/1561122 (82%)]\tLoss: 0.049772\n",
      "Train Epoch: 26 [1536000/1561122 (98%)]\tLoss: 0.052902\n",
      "test loss:0.051077619194984436\n",
      "Train Epoch: 27 [0/1561122 (0%)]\tLoss: 0.050718\n",
      "Train Epoch: 27 [256000/1561122 (16%)]\tLoss: 0.048629\n",
      "Train Epoch: 27 [512000/1561122 (33%)]\tLoss: 0.047478\n",
      "Train Epoch: 27 [768000/1561122 (49%)]\tLoss: 0.054276\n",
      "Train Epoch: 27 [1024000/1561122 (66%)]\tLoss: 0.048333\n",
      "Train Epoch: 27 [1280000/1561122 (82%)]\tLoss: 0.047583\n",
      "Train Epoch: 27 [1536000/1561122 (98%)]\tLoss: 0.049238\n",
      "test loss:0.05062412470579147\n",
      "Train Epoch: 28 [0/1561122 (0%)]\tLoss: 0.048525\n",
      "Train Epoch: 28 [256000/1561122 (16%)]\tLoss: 0.044903\n",
      "Train Epoch: 28 [512000/1561122 (33%)]\tLoss: 0.047997\n",
      "Train Epoch: 28 [768000/1561122 (49%)]\tLoss: 0.050428\n",
      "Train Epoch: 28 [1024000/1561122 (66%)]\tLoss: 0.050680\n",
      "Train Epoch: 28 [1280000/1561122 (82%)]\tLoss: 0.052380\n",
      "Train Epoch: 28 [1536000/1561122 (98%)]\tLoss: 0.044415\n",
      "test loss:0.045042794197797775\n",
      "Train Epoch: 29 [0/1561122 (0%)]\tLoss: 0.040569\n",
      "Train Epoch: 29 [256000/1561122 (16%)]\tLoss: 0.044819\n",
      "Train Epoch: 29 [512000/1561122 (33%)]\tLoss: 0.050100\n",
      "Train Epoch: 29 [768000/1561122 (49%)]\tLoss: 0.049611\n",
      "Train Epoch: 29 [1024000/1561122 (66%)]\tLoss: 0.048977\n",
      "Train Epoch: 29 [1280000/1561122 (82%)]\tLoss: 0.054212\n",
      "Train Epoch: 29 [1536000/1561122 (98%)]\tLoss: 0.050289\n",
      "test loss:0.05304340273141861\n",
      "Train Epoch: 30 [0/1561122 (0%)]\tLoss: 0.052352\n",
      "Train Epoch: 30 [256000/1561122 (16%)]\tLoss: 0.043337\n",
      "Train Epoch: 30 [512000/1561122 (33%)]\tLoss: 0.044537\n",
      "Train Epoch: 30 [768000/1561122 (49%)]\tLoss: 0.044455\n",
      "Train Epoch: 30 [1024000/1561122 (66%)]\tLoss: 0.045471\n",
      "Train Epoch: 30 [1280000/1561122 (82%)]\tLoss: 0.043645\n",
      "Train Epoch: 30 [1536000/1561122 (98%)]\tLoss: 0.039007\n",
      "test loss:0.05660805478692055\n",
      "Train Epoch: 31 [0/1561122 (0%)]\tLoss: 0.063315\n",
      "Train Epoch: 31 [256000/1561122 (16%)]\tLoss: 0.051335\n",
      "Train Epoch: 31 [512000/1561122 (33%)]\tLoss: 0.047593\n",
      "Train Epoch: 31 [768000/1561122 (49%)]\tLoss: 0.047402\n",
      "Train Epoch: 31 [1024000/1561122 (66%)]\tLoss: 0.065798\n",
      "Train Epoch: 31 [1280000/1561122 (82%)]\tLoss: 0.054083\n",
      "Train Epoch: 31 [1536000/1561122 (98%)]\tLoss: 0.044775\n",
      "test loss:0.058487508445978165\n",
      "Train Epoch: 32 [0/1561122 (0%)]\tLoss: 0.059403\n",
      "Train Epoch: 32 [256000/1561122 (16%)]\tLoss: 0.047526\n",
      "Train Epoch: 32 [512000/1561122 (33%)]\tLoss: 0.046234\n",
      "Train Epoch: 32 [768000/1561122 (49%)]\tLoss: 0.041790\n",
      "Train Epoch: 32 [1024000/1561122 (66%)]\tLoss: 0.046814\n",
      "Train Epoch: 32 [1280000/1561122 (82%)]\tLoss: 0.047752\n",
      "Train Epoch: 32 [1536000/1561122 (98%)]\tLoss: 0.053601\n",
      "test loss:0.04916886240243912\n",
      "Train Epoch: 33 [0/1561122 (0%)]\tLoss: 0.048771\n",
      "Train Epoch: 33 [256000/1561122 (16%)]\tLoss: 0.048951\n",
      "Train Epoch: 33 [512000/1561122 (33%)]\tLoss: 0.040590\n",
      "Train Epoch: 33 [768000/1561122 (49%)]\tLoss: 0.046890\n",
      "Train Epoch: 33 [1024000/1561122 (66%)]\tLoss: 0.048257\n",
      "Train Epoch: 33 [1280000/1561122 (82%)]\tLoss: 0.040875\n",
      "Train Epoch: 33 [1536000/1561122 (98%)]\tLoss: 0.056071\n",
      "test loss:0.04599655047059059\n",
      "Train Epoch: 34 [0/1561122 (0%)]\tLoss: 0.046664\n",
      "Train Epoch: 34 [256000/1561122 (16%)]\tLoss: 0.046002\n",
      "Train Epoch: 34 [512000/1561122 (33%)]\tLoss: 0.041806\n",
      "Train Epoch: 34 [768000/1561122 (49%)]\tLoss: 0.041672\n",
      "Train Epoch: 34 [1024000/1561122 (66%)]\tLoss: 0.046658\n",
      "Train Epoch: 34 [1280000/1561122 (82%)]\tLoss: 0.043017\n",
      "Train Epoch: 34 [1536000/1561122 (98%)]\tLoss: 0.047561\n",
      "test loss:0.0547759123146534\n",
      "Train Epoch: 35 [0/1561122 (0%)]\tLoss: 0.055664\n",
      "Train Epoch: 35 [256000/1561122 (16%)]\tLoss: 0.044719\n",
      "Train Epoch: 35 [512000/1561122 (33%)]\tLoss: 0.045171\n",
      "Train Epoch: 35 [768000/1561122 (49%)]\tLoss: 0.044864\n",
      "Train Epoch: 35 [1024000/1561122 (66%)]\tLoss: 0.044272\n",
      "Train Epoch: 35 [1280000/1561122 (82%)]\tLoss: 0.048403\n",
      "Train Epoch: 35 [1536000/1561122 (98%)]\tLoss: 0.049465\n",
      "test loss:0.048192430287599564\n",
      "Train Epoch: 36 [0/1561122 (0%)]\tLoss: 0.049181\n",
      "Train Epoch: 36 [256000/1561122 (16%)]\tLoss: 0.041327\n",
      "Train Epoch: 36 [512000/1561122 (33%)]\tLoss: 0.044192\n",
      "Train Epoch: 36 [768000/1561122 (49%)]\tLoss: 0.053598\n",
      "Train Epoch: 36 [1024000/1561122 (66%)]\tLoss: 0.044458\n",
      "Train Epoch: 36 [1280000/1561122 (82%)]\tLoss: 0.047103\n",
      "Train Epoch: 36 [1536000/1561122 (98%)]\tLoss: 0.049797\n",
      "test loss:0.05171941965818405\n",
      "Train Epoch: 37 [0/1561122 (0%)]\tLoss: 0.050704\n",
      "Train Epoch: 37 [256000/1561122 (16%)]\tLoss: 0.040629\n",
      "Train Epoch: 37 [512000/1561122 (33%)]\tLoss: 0.058277\n",
      "Train Epoch: 37 [768000/1561122 (49%)]\tLoss: 0.048343\n",
      "Train Epoch: 37 [1024000/1561122 (66%)]\tLoss: 0.042960\n",
      "Train Epoch: 37 [1280000/1561122 (82%)]\tLoss: 0.047204\n",
      "Train Epoch: 37 [1536000/1561122 (98%)]\tLoss: 0.042306\n",
      "test loss:0.04586374759674072\n",
      "Train Epoch: 38 [0/1561122 (0%)]\tLoss: 0.044481\n",
      "Train Epoch: 38 [256000/1561122 (16%)]\tLoss: 0.045353\n",
      "Train Epoch: 38 [512000/1561122 (33%)]\tLoss: 0.041511\n",
      "Train Epoch: 38 [768000/1561122 (49%)]\tLoss: 0.045045\n",
      "Train Epoch: 38 [1024000/1561122 (66%)]\tLoss: 0.045820\n",
      "Train Epoch: 38 [1280000/1561122 (82%)]\tLoss: 0.049474\n",
      "Train Epoch: 38 [1536000/1561122 (98%)]\tLoss: 0.043152\n",
      "test loss:0.05611768737435341\n",
      "Train Epoch: 39 [0/1561122 (0%)]\tLoss: 0.060008\n",
      "Train Epoch: 39 [256000/1561122 (16%)]\tLoss: 0.040830\n",
      "Train Epoch: 39 [512000/1561122 (33%)]\tLoss: 0.053519\n",
      "Train Epoch: 39 [768000/1561122 (49%)]\tLoss: 0.043869\n",
      "Train Epoch: 39 [1024000/1561122 (66%)]\tLoss: 0.050649\n",
      "Train Epoch: 39 [1280000/1561122 (82%)]\tLoss: 0.055212\n",
      "Train Epoch: 39 [1536000/1561122 (98%)]\tLoss: 0.052124\n",
      "test loss:0.05078454315662384\n",
      "Train Epoch: 40 [0/1561122 (0%)]\tLoss: 0.050411\n",
      "Train Epoch: 40 [256000/1561122 (16%)]\tLoss: 0.042491\n",
      "Train Epoch: 40 [512000/1561122 (33%)]\tLoss: 0.038015\n",
      "Train Epoch: 40 [768000/1561122 (49%)]\tLoss: 0.041194\n",
      "Train Epoch: 40 [1024000/1561122 (66%)]\tLoss: 0.050297\n",
      "Train Epoch: 40 [1280000/1561122 (82%)]\tLoss: 0.036744\n",
      "Train Epoch: 40 [1536000/1561122 (98%)]\tLoss: 0.049043\n",
      "test loss:0.042521148920059204\n",
      "Train Epoch: 41 [0/1561122 (0%)]\tLoss: 0.040907\n",
      "Train Epoch: 41 [256000/1561122 (16%)]\tLoss: 0.044848\n",
      "Train Epoch: 41 [512000/1561122 (33%)]\tLoss: 0.049438\n",
      "Train Epoch: 41 [768000/1561122 (49%)]\tLoss: 0.042101\n",
      "Train Epoch: 41 [1024000/1561122 (66%)]\tLoss: 0.044836\n",
      "Train Epoch: 41 [1280000/1561122 (82%)]\tLoss: 0.042828\n",
      "Train Epoch: 41 [1536000/1561122 (98%)]\tLoss: 0.047391\n",
      "test loss:0.04927317053079605\n",
      "Train Epoch: 42 [0/1561122 (0%)]\tLoss: 0.049689\n",
      "Train Epoch: 42 [256000/1561122 (16%)]\tLoss: 0.047431\n",
      "Train Epoch: 42 [512000/1561122 (33%)]\tLoss: 0.051922\n",
      "Train Epoch: 42 [768000/1561122 (49%)]\tLoss: 0.039952\n",
      "Train Epoch: 42 [1024000/1561122 (66%)]\tLoss: 0.040883\n",
      "Train Epoch: 42 [1280000/1561122 (82%)]\tLoss: 0.042139\n",
      "Train Epoch: 42 [1536000/1561122 (98%)]\tLoss: 0.043669\n",
      "test loss:0.04842274636030197\n",
      "Train Epoch: 43 [0/1561122 (0%)]\tLoss: 0.049901\n",
      "Train Epoch: 43 [256000/1561122 (16%)]\tLoss: 0.046872\n",
      "Train Epoch: 43 [512000/1561122 (33%)]\tLoss: 0.045599\n",
      "Train Epoch: 43 [768000/1561122 (49%)]\tLoss: 0.044526\n",
      "Train Epoch: 43 [1024000/1561122 (66%)]\tLoss: 0.041271\n",
      "Train Epoch: 43 [1280000/1561122 (82%)]\tLoss: 0.052782\n",
      "Train Epoch: 43 [1536000/1561122 (98%)]\tLoss: 0.047333\n",
      "test loss:0.046699684113264084\n",
      "Train Epoch: 44 [0/1561122 (0%)]\tLoss: 0.049246\n",
      "Train Epoch: 44 [256000/1561122 (16%)]\tLoss: 0.045744\n",
      "Train Epoch: 44 [512000/1561122 (33%)]\tLoss: 0.047712\n",
      "Train Epoch: 44 [768000/1561122 (49%)]\tLoss: 0.040870\n",
      "Train Epoch: 44 [1024000/1561122 (66%)]\tLoss: 0.040840\n",
      "Train Epoch: 44 [1280000/1561122 (82%)]\tLoss: 0.037464\n",
      "Train Epoch: 44 [1536000/1561122 (98%)]\tLoss: 0.051676\n",
      "test loss:0.05842002481222153\n",
      "Train Epoch: 45 [0/1561122 (0%)]\tLoss: 0.059827\n",
      "Train Epoch: 45 [256000/1561122 (16%)]\tLoss: 0.040875\n",
      "Train Epoch: 45 [512000/1561122 (33%)]\tLoss: 0.040089\n",
      "Train Epoch: 45 [768000/1561122 (49%)]\tLoss: 0.040519\n",
      "Train Epoch: 45 [1024000/1561122 (66%)]\tLoss: 0.044174\n",
      "Train Epoch: 45 [1280000/1561122 (82%)]\tLoss: 0.039416\n",
      "Train Epoch: 45 [1536000/1561122 (98%)]\tLoss: 0.044087\n",
      "test loss:0.03927509859204292\n",
      "Train Epoch: 46 [0/1561122 (0%)]\tLoss: 0.038272\n",
      "Train Epoch: 46 [256000/1561122 (16%)]\tLoss: 0.034486\n",
      "Train Epoch: 46 [512000/1561122 (33%)]\tLoss: 0.046235\n",
      "Train Epoch: 46 [768000/1561122 (49%)]\tLoss: 0.040976\n",
      "Train Epoch: 46 [1024000/1561122 (66%)]\tLoss: 0.040639\n",
      "Train Epoch: 46 [1280000/1561122 (82%)]\tLoss: 0.041068\n",
      "Train Epoch: 46 [1536000/1561122 (98%)]\tLoss: 0.045468\n",
      "test loss:0.04389338940382004\n",
      "Train Epoch: 47 [0/1561122 (0%)]\tLoss: 0.041068\n",
      "Train Epoch: 47 [256000/1561122 (16%)]\tLoss: 0.042065\n",
      "Train Epoch: 47 [512000/1561122 (33%)]\tLoss: 0.042493\n",
      "Train Epoch: 47 [768000/1561122 (49%)]\tLoss: 0.034222\n",
      "Train Epoch: 47 [1024000/1561122 (66%)]\tLoss: 0.034031\n",
      "Train Epoch: 47 [1280000/1561122 (82%)]\tLoss: 0.040837\n",
      "Train Epoch: 47 [1536000/1561122 (98%)]\tLoss: 0.046274\n",
      "test loss:0.039271123707294464\n",
      "Train Epoch: 48 [0/1561122 (0%)]\tLoss: 0.039389\n",
      "Train Epoch: 48 [256000/1561122 (16%)]\tLoss: 0.040186\n",
      "Train Epoch: 48 [512000/1561122 (33%)]\tLoss: 0.044137\n",
      "Train Epoch: 48 [768000/1561122 (49%)]\tLoss: 0.040106\n",
      "Train Epoch: 48 [1024000/1561122 (66%)]\tLoss: 0.042847\n",
      "Train Epoch: 48 [1280000/1561122 (82%)]\tLoss: 0.043787\n",
      "Train Epoch: 48 [1536000/1561122 (98%)]\tLoss: 0.039616\n",
      "test loss:0.04019227996468544\n",
      "Train Epoch: 49 [0/1561122 (0%)]\tLoss: 0.040338\n",
      "Train Epoch: 49 [256000/1561122 (16%)]\tLoss: 0.043368\n",
      "Train Epoch: 49 [512000/1561122 (33%)]\tLoss: 0.038052\n",
      "Train Epoch: 49 [768000/1561122 (49%)]\tLoss: 0.038809\n",
      "Train Epoch: 49 [1024000/1561122 (66%)]\tLoss: 0.041668\n",
      "Train Epoch: 49 [1280000/1561122 (82%)]\tLoss: 0.040554\n",
      "Train Epoch: 49 [1536000/1561122 (98%)]\tLoss: 0.043157\n",
      "test loss:0.048332080245018005\n",
      "Train Epoch: 50 [0/1561122 (0%)]\tLoss: 0.048376\n",
      "Train Epoch: 50 [256000/1561122 (16%)]\tLoss: 0.040728\n",
      "Train Epoch: 50 [512000/1561122 (33%)]\tLoss: 0.038333\n",
      "Train Epoch: 50 [768000/1561122 (49%)]\tLoss: 0.041857\n",
      "Train Epoch: 50 [1024000/1561122 (66%)]\tLoss: 0.040751\n",
      "Train Epoch: 50 [1280000/1561122 (82%)]\tLoss: 0.035970\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "best_loss = 1\n",
    "\n",
    "for epoch in range(1, 50 + 1):\n",
    "    train(model, device, train_dataloader, optimizer, epoch)\n",
    "    best_loss = test(model, device, test_dataloader, optimizer, epoch, best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('SDF.torch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0132]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model = model.eval()\n",
    "model(torch.from_numpy(np.array([2.3454492 , -0.96645486,  8.859472])).unsqueeze(0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(SDFs):\n",
    "    if x<-0.2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0081353"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SDFs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.3454492 , -0.96645486,  8.859472  ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
